# Heat-Waves
This repository is my senior year project: a heatwave-predicting neural network. It is still very much under development, but I've tried to keep everything as organized as possible. The initial data processing is in ```dataprep.jl```; the loss functions are in ```loss.jl```; the data management is in ```data.jl```; the training functions are in ```train.jl```; and the individual gpu and cpu training processes are in ```hwcpu.jl``` and ```hwgpu.jl``` respectively. My dataset is from Kaggle, <a href="https://www.kaggle.com/datasets/hansukyang/temperature-history-of-1000-cities-1980-to-2020">Temperature History of 1000 cities 1980 to 2020</a>.
# Methodology
I am training my model using the last 40 years of daily temperatures from 1000 cities around the world. The model is a simple LSTM, with a dense input and output layer. It is learning from the first 36 years——1980 to 2016——and testing on the most recent four——2016 to 2020. The model takes uses much context as possible before making a decision——that means that before making a prediction, it processes <i>all</i> of the prior data. While standard gradient descent is typically much less performant than the stochastic version, this sequential processing flips the script——taking the gradient of a random sample batch is only slightly slower than taking the gradient for every sample. For that reason, there are two easily accesible training methods, one both standard and stochastic gradient descent.
On top of the predicting LSTM, there is an autoencoder network which, to lessen computational load and improve accuracy, embeds the city heat data into vectors a quarter the size. This performs a role along the lines of forming a world heat map out of the individual points.
